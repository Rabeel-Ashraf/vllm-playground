{
    "configurations": [
        {
            "name": "Small Test Model",
            "description": "Fast loading model for testing",
            "config": {
                "model": "facebook/opt-125m",
                "tensor_parallel_size": 1,
                "gpu_memory_utilization": 0.5,
                "dtype": "auto"
            }
        },
        {
            "name": "Llama 2 7B Chat",
            "description": "Production-ready 7B chat model",
            "config": {
                "model": "meta-llama/Llama-2-7b-chat-hf",
                "tensor_parallel_size": 1,
                "gpu_memory_utilization": 0.9,
                "dtype": "auto",
                "enable_prefix_caching": true
            }
        },
        {
            "name": "Mistral 7B Instruct",
            "description": "High-quality instruct model",
            "config": {
                "model": "mistralai/Mistral-7B-Instruct-v0.2",
                "tensor_parallel_size": 1,
                "gpu_memory_utilization": 0.9,
                "dtype": "auto",
                "enable_prefix_caching": true
            }
        },
        {
            "name": "Llama 2 13B (Multi-GPU)",
            "description": "Larger model with tensor parallelism",
            "config": {
                "model": "meta-llama/Llama-2-13b-chat-hf",
                "tensor_parallel_size": 2,
                "gpu_memory_utilization": 0.9,
                "dtype": "auto",
                "enable_prefix_caching": true
            }
        },
        {
            "name": "Code Llama 7B",
            "description": "Optimized for code generation",
            "config": {
                "model": "codellama/CodeLlama-7b-Instruct-hf",
                "tensor_parallel_size": 1,
                "gpu_memory_utilization": 0.9,
                "dtype": "auto"
            }
        }
    ],
    "generation_presets": [
        {
            "name": "Precise",
            "temperature": 0.1,
            "max_tokens": 512
        },
        {
            "name": "Balanced",
            "temperature": 0.7,
            "max_tokens": 512
        },
        {
            "name": "Creative",
            "temperature": 1.2,
            "max_tokens": 1024
        },
        {
            "name": "Long Form",
            "temperature": 0.7,
            "max_tokens": 2048
        }
    ]
}

